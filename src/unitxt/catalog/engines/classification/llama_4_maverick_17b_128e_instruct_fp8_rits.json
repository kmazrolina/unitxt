{
    "__type__": "cross_provider_inference_engine",
    "model": "llama-4-maverick",
    "logprobs": true,
    "max_tokens": 5,
    "temperature": 0.0,
    "top_logprobs": 5,
    "provider": "rits"
}
